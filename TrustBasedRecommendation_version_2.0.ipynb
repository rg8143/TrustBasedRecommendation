{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dzTyNro1RvY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating file for taking outputs \n",
    "\n",
    "file = open(\"output.txt\",'w')\n",
    "file.write(\"Dataset Used is custom_trust and custom_rating\\n\")\n",
    "file.write(\"Loading the rating and trust dataset.....\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading The Rating and Trust Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "YE96i5bu1Rve",
    "outputId": "bf73c9de-79df-493b-bf0a-a68d7fc15edf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Loading the dataset\n",
    "\n",
    "# df_trust = pd.read_csv(\"custom_trust.csv\")\n",
    "# df_rating = pd.read_csv(\"custom_rating.csv\")\n",
    "# file.write(\"Dataset Loaded Successfully!!!\\n\")\n",
    "\n",
    "\n",
    "#Loading the dataset\n",
    "\n",
    "df_trust=pd.read_csv(\"trust_data.txt\",delim_whitespace=True,encoding=\"utf-8\", skipinitialspace=True)\n",
    "\n",
    "df_rating = pd.read_csv(\"ratings_data.txt\")\n",
    "df_rating = df_rating[df_rating.userId<=100]\n",
    "df_rating = df_rating.reset_index(drop=True)\n",
    "file.write(\"Dataset Loaded Successfully!!!\\n\")\n",
    "df_trust = df_trust[(df_trust.user1<=100)&(df_trust.user2<=100)]\n",
    "df_trust = df_trust.reset_index(drop=True)\n",
    "# df_rating\n",
    "# df_trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as the partitioning of dataset is only done for rating not for trust so below line finds the overall users in the system\n",
    "total_users_for_trust = df_rating.userId.unique().shape[0]\n",
    "\n",
    "file.write(\"Dividing The Rating Dataset into training and test.....\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing The Rating Dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "colab_type": "code",
    "id": "BawsKQRb1Rvn",
    "outputId": "92cbabb6-3de4-48fa-ecbb-f6585850ed05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #dividing the dataset into training and test(80:20)\n",
    "# train=df_rating[0:26]\n",
    "# test=df_rating[26:32]\n",
    "\n",
    "# #df_rating is the training part of rating dataset and test is the testing part of the dataset\n",
    "# df_rating=train\n",
    "\n",
    "# file.write(\"completed!!!\\n\")\n",
    "\n",
    "\n",
    "#dividing the dataset into training and test(80:20)\n",
    "train=df_rating[0:7903]\n",
    "test=df_rating[7903:]\n",
    "\n",
    "#df_rating is the training part of rating dataset and test is the testing part of the dataset\n",
    "df_rating=train\n",
    "\n",
    "file.write(\"completed!!!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing the matrices for trust propagation,similarity and user pair distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0pb6hda1Rvt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_users calculates the total users in the training dataset \n",
    "#unique_user_list finds the unique users from the training dataset as there are redundant rows of the same user in the rating dataset\n",
    "\n",
    "file.write(\"Intializing the matrices for trust propagation,similarity and user pair distances.................\\n\")\n",
    "\n",
    "total_users = df_rating.userId.unique().shape[0]\n",
    "unique_user_list = df_rating.userId.unique().tolist()\n",
    "\n",
    "# following matrix i.e similarity is used for holding the pcc between a pair of users\n",
    "# similarity = [[0 for x in range(total_users)] for y in range(total_users)]\n",
    "similarity = np.zeros((total_users,total_users))\n",
    "\n",
    "# following matrix i.e trust_in_users is used for holding the chain of trust between a pair of users\n",
    "# trust_in_users = [[0 for x in range(total_users_for_trust)] for y in range(total_users_for_trust)]\n",
    "trust_in_users = np.zeros((total_users_for_trust,total_users_for_trust))\n",
    "\n",
    "# following matrix i.e user_pair_distance is used for holding the distance between a pair of users\n",
    "#the formula used for calculating the distances between users is taken from novel 2d graph research paper\n",
    "#distance of 9 tells that there is no way between pair of users to calculate distance so 9 denotes the infinity\n",
    "# user_pair_distance = [[0 for x in range(total_users)] for y in range(total_users)]\n",
    "user_pair_distance = np.zeros((total_users,total_users))\n",
    "\n",
    "\n",
    "file.write(\"completed!!!\\n\")\n",
    "\n",
    "file.write(\"Construction of Novel 2D Graph started........\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of Novel 2D Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "nl1nb-A11Rvv",
    "outputId": "103c525a-c059-4c7c-e738-47f39dd1a232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   1.   1.   1.   0.5  0.   0.33 1.   0.5  0.5 ]\n",
      " [1.   1.   0.5  1.   1.   0.   0.5  0.5  1.   0.33]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.33 0.   0.5  0.   1.   0.   1.   1.   0.5  0.5 ]\n",
      " [0.   0.   0.   1.   0.   1.   0.   0.   0.   0.  ]\n",
      " [0.5  0.33 1.   0.33 0.   0.   1.   1.   1.   0.5 ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.   0.   1.  ]\n",
      " [1.   0.5  0.5  0.5  0.33 0.   0.   0.5  1.   0.33]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#module for calculating similarity currently pearson similarity is used\n",
    "\n",
    "# # g is a graph that is used to show pcc similarity between users\n",
    "# g = nx.DiGraph()\n",
    "# g.add_nodes_from(unique_user_list)\n",
    "\n",
    "\n",
    "#this function calculates similarity between the pair of user as needed using the pearson similarity coefficient\n",
    "def calculateSimilarity(i,j,dataset1,dataset2):\n",
    "    firstUser = dataset1[dataset1.userId==i]\n",
    "    firstUser.columns = ['userId1','movieId','rating1']\n",
    "    secondUser = dataset2[dataset2.userId==j]\n",
    "    secondUser.columns = ['userId2','movieId','rating2']\n",
    "    userRatings = pd.merge(firstUser,secondUser,on ='movieId')\n",
    "    if(userRatings.shape[0]>1):\n",
    "        temp_pcc = np.corrcoef(userRatings['rating1'].tolist(),userRatings['rating2'].tolist())[0, 1]\n",
    "        pcc=round(temp_pcc,2)\n",
    "    else:\n",
    "        pcc = 0\n",
    "    return pcc\n",
    "\n",
    "    \n",
    "# this is used to calculate similarity between every pair of users\n",
    "for i in range(0,total_users):\n",
    "    for j in range(0,total_users):\n",
    "        if(i==j):\n",
    "            similarity[i][j]=round(1.000, 2)\n",
    "        else:\n",
    "            y= round(calculateSimilarity(i+1,j+1,df_rating,df_rating), 2)\n",
    "            if(not np.isnan(y)):\n",
    "                similarity[i][j]= y\n",
    "#      \n",
    "# #for adding edges and weights to the graph g\n",
    "# for i in range(0,total_users):\n",
    "#     for j in range(i+1,total_users):\n",
    "#         if(similarity[i][j]>0):\n",
    "#             g.add_edge(i+1,j+1, weight=similarity[i][j])\n",
    "\n",
    "            \n",
    "# #this code shows the edge labels and final visualization of the graph \n",
    "# #here edge weights are pearson coorelation coefficient\n",
    "# pos = nx.circular_layout(g)\n",
    "# nx.draw(g,pos,with_labels=True)\n",
    "# nx.draw_networkx_edge_labels(g,pos)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"pcc_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()  \n",
    "\n",
    "# print(similarity)\n",
    "file.write(\"-----------------Printing the similarity matrix------------------------------\\n\")\n",
    "\n",
    "for item in similarity:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#module for calculating chain of trust between users\n",
    "\n",
    "# # t is a graph that is used to show trust between users\n",
    "t = nx.DiGraph()\n",
    "t.add_nodes_from(unique_user_list)\n",
    "\n",
    "rows_in_trust = df_trust.shape[0]\n",
    "\n",
    "for i in range(0,rows_in_trust):\n",
    "    t.add_edge(df_trust.loc[i, 'user1'],df_trust.loc[i, 'user2'])\n",
    "\n",
    "\n",
    "# pos = nx.circular_layout(t)\n",
    "# nx.draw(t,pos,with_labels=True)\n",
    "# # nx.draw_networkx_edge_labels(t,pos)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"trust_chain_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()\n",
    "\n",
    "# here input x is based on the six degree theory\n",
    "# if x is 2 then it means while calculating trust between two user\n",
    "# a and b there can be atmost 2 node present between them\n",
    "def calculateTrustChain(x):\n",
    "    for i in range(1,total_users_for_trust+1):\n",
    "        for j in range(1,total_users_for_trust+1):\n",
    "            if(i!=j):\n",
    "                try:\n",
    "                    path_length = nx.shortest_path_length(t,source=i,target=j)\n",
    "                    if(path_length <= x+1):\n",
    "                        trust_in_users[i-1][j-1] = round(pow(path_length,-1),2)\n",
    "                    else:\n",
    "                        trust_in_users[i-1][j-1] = 0\n",
    "                except nx.NetworkXNoPath:\n",
    "                    trust_in_users[i-1][j-1] = 0\n",
    "            else:\n",
    "                trust_in_users[i-1][j-1] = 1\n",
    "                \n",
    "                    \n",
    "\n",
    "                    \n",
    "file.write(\"\\n---------calculating chain of trust using at max 2 hops between two users----------\\n\")      \n",
    "calculateTrustChain(2)\n",
    "print(trust_in_users)\n",
    "\n",
    "file.write(\"-----------------Printing the trust_in_users matrix------------------------------\\n\")\n",
    "\n",
    "for item in trust_in_users:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "# #every edge of combined_graph is double weighted i.e having similarity and trust as its weights\n",
    "# #and the users as its nodes\n",
    "# combined_graph = nx.DiGraph()\n",
    "# combined_graph.add_nodes_from(unique_user_list)\n",
    "\n",
    "# #this loop adds edges between two nodes if there exist any edge\n",
    "# for i in range(0,total_users):\n",
    "#     for j in range(0,total_users):\n",
    "#         if(i!=j):\n",
    "#             if((trust_in_users[i][j]!=0) or (similarity[i][j]!=0)):\n",
    "#                 combined_graph.add_edge(i+1,j+1, label='('+str(similarity[i][j])+','+str(trust_in_users[i][j])+')')\n",
    "                \n",
    "# #this code shows the combined graph in circular fashion\n",
    "# pos = nx.circular_layout(combined_graph)\n",
    "# nx.draw(combined_graph,pos,with_labels=True,node_size=100,font_size=10)\n",
    "# nx.draw_networkx_edge_labels(combined_graph,pos,font_size=8)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"pcc_and_trust_combined_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "# This module is to make clusters out of given novel 2d graph\n",
    "\n",
    "#these loops are calculating the distances between a pair of users\n",
    "#the formula used for calculating distance is taken from novel 2d graph algorithm\n",
    "#distance of 9 tells that there is no way between pair of users to calculate distance so it denotes infinity\n",
    "\n",
    "\n",
    "for i in range(0,total_users):\n",
    "    for j in range(0,total_users):\n",
    "        if(similarity[i][j]!=0 or trust_in_users[i][j]!=0):\n",
    "            d_s = 1-similarity[i][j]\n",
    "            d_t = 1-trust_in_users[i][j]\n",
    "            d_s_2 = d_s**2\n",
    "            d_t_2 = d_t**2\n",
    "            temp = d_s_2+d_t_2\n",
    "            distance = round(temp**0.5,2)\n",
    "            user_pair_distance[i][j]=distance\n",
    "        else:\n",
    "            #here distance of 9 tells that there is no way between this pair of users so infinite distance\n",
    "            user_pair_distance[i][j]=9\n",
    "            \n",
    "\n",
    "\n",
    "# print(user_pair_distance)\n",
    "\n",
    "file.write(\"Construction of Novel 2D Graph Completed!!!!\\n\")\n",
    "file.write(\"-----------------Printing the user_pair_distance matrix------------------------------\\n\")\n",
    "\n",
    "for item in user_pair_distance:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Feasible Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.write(\"Started Generating Feasible Partitioning............\\n\")\n",
    "\n",
    "def kmedoids(number_of_clusters):\n",
    "    chosen_clusters=[]\n",
    "    final_clusters=[]\n",
    "    for i in range(0,number_of_clusters):\n",
    "        x=random.randint(1,total_users)\n",
    "        while(x in chosen_clusters):\n",
    "            x=random.randint(1,total_users)\n",
    "        chosen_clusters.append(x)\n",
    "    for j in chosen_clusters:\n",
    "        final_clusters.append([j])\n",
    "    cont=True\n",
    "    while(cont):\n",
    "        for i in range(0,total_users):\n",
    "            if(not any(i+1 in sublist for sublist in final_clusters)):\n",
    "                min_distance=10\n",
    "                allocate_cluster=0\n",
    "                for j in range(0,number_of_clusters):\n",
    "                    temp_cluster=final_clusters[j][0]\n",
    "                    if(min_distance>=user_pair_distance[i][temp_cluster-1]):\n",
    "                        min_distance=user_pair_distance[i][temp_cluster-1]\n",
    "                        allocate_cluster=j\n",
    "                final_clusters[allocate_cluster].append(i+1)\n",
    "        cont=False\n",
    "        row_num=0\n",
    "        modification_dict={}\n",
    "        for i in final_clusters:\n",
    "            min_cluster_distance=99999\n",
    "            for j in range(0,len(i)):\n",
    "                total_sum=0\n",
    "                avg=0\n",
    "                for k in range(0,len(i)):\n",
    "                    if(i[j]!=i[k]):\n",
    "                        total_sum +=user_pair_distance[i[j]-1][i[k]-1]\n",
    "                avg=total_sum/len(i)\n",
    "                if(min_cluster_distance>avg):\n",
    "                    min_cluster_distance=avg\n",
    "                    min_cluster=i[j]\n",
    "            if(min_cluster!=i[0]):\n",
    "                cont=True\n",
    "                modification_dict[row_num]=min_cluster                \n",
    "            row_num+=1            \n",
    "        if(cont):\n",
    "            final_clusters=[]\n",
    "            for z in chosen_clusters:\n",
    "                    final_clusters.append([z])\n",
    "            for key in modification_dict:\n",
    "                    final_clusters[key][0]=modification_dict[key]\n",
    "#     print(chosen_clusters)\n",
    "#     print(final_clusters)\n",
    "#     for i in range(0,len(final_clusters)):\n",
    "#         cluster_centers.append(final_clusters[i][0])\n",
    "    return final_clusters    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this code checks the distance of each user in the test dataset with the \n",
    "#clusters and assigns nearest cluster to the user in the test dataset\n",
    "\n",
    "def testUserDict(cluster_centers):\n",
    "    \n",
    "    testSetUser=test.userId.unique().tolist()\n",
    "    targetClusterTestUserDict={}\n",
    "    \n",
    "#     print(cluster_centers)\n",
    "\n",
    "\n",
    "    for i in range(0,len(testSetUser)):\n",
    "        nearestClusterIndex=0\n",
    "        minDistance=10\n",
    "        for j in range(0,len(cluster_centers)):\n",
    "\n",
    "            pcc_simi=calculateSimilarity(testSetUser[i],cluster_centers[j][0],test,df_rating)\n",
    "            temp1=testSetUser[i]-1\n",
    "            temp2=cluster_centers[j][0]-1\n",
    "            trust_simi=trust_in_users[temp1][temp2]\n",
    "            if(pcc_simi!=0 or trust_simi!=0):\n",
    "                d_s = 1-pcc_simi\n",
    "                d_t = 1-trust_simi\n",
    "                d_s_2 = d_s**2\n",
    "                d_t_2 = d_t**2\n",
    "                temp = d_s_2+d_t_2\n",
    "                distance = round(temp**0.5,2)\n",
    "            else:\n",
    "                #here distance of 9 tells that there is no way between this pair of users so infinite distance\n",
    "                distance=9\n",
    "            if(minDistance>distance):\n",
    "                minDistance=distance\n",
    "                nearestClusterIndex=j\n",
    "        targetClusterTestUserDict[testSetUser[i]]=nearestClusterIndex\n",
    "\n",
    "    return targetClusterTestUserDict\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#it calculates rating coverage for the system using the test dataset\n",
    "def rating_coverage(clusters,targetClusterTestUserDict):\n",
    "    count=0\n",
    "    length=test.shape[0]\n",
    "    for i in range(0,length):\n",
    "        userBelongsToCluster=targetClusterTestUserDict[test.iloc[i]['userId']]\n",
    "        itemid=test.iloc[i]['movieId']\n",
    "        for j in clusters[userBelongsToCluster]:\n",
    "            rowNum=df_rating[(df_rating.userId==j)&(df_rating.movieId==itemid)].empty\n",
    "            if(not rowNum):\n",
    "                count+=1\n",
    "                break;       \n",
    "    rc=count/length\n",
    "    rc=round(rc,2)\n",
    "    return rc*100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#it checks and decides optimal number of clusters according to given rate of coverage\n",
    "def feasible_partitioning(MARC):\n",
    "    rc=100\n",
    "    i=1\n",
    "    partition1=[]\n",
    "    partition2=[]\n",
    "    while(rc>=MARC):\n",
    "        i=i+1\n",
    "        partition2=kmedoids(i)\n",
    "        targetClusterTestUserDict=testUserDict(partition2)\n",
    "        rc = rating_coverage(partition2,targetClusterTestUserDict)\n",
    "        partition1=partition2\n",
    "    final_cluster=partition1\n",
    "    return partition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file.write(\"------------------------Started Generating Feasible Partitioning--------------------------------------------\\n\")\n",
    "\n",
    "# abc=feasible_partitioning(70)\n",
    "# file.write(\"Completed Feasible Partitioning!!!\\n\")\n",
    "\n",
    "# file.write(\"-----------------------Printing the output of feasible partitioning at MARC=70--------------------\\n\")\n",
    "# # abc\n",
    "\n",
    "# for item in abc:\n",
    "#     for sub_item in item:\n",
    "#         file.write(\"%s\\t\" % sub_item)\n",
    "#     file.write(\"\\n\")\n",
    "\n",
    "# file.write(\"\\n\\n\\n\")\n",
    "\n",
    "# file.write(\"---------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating optimal parameters i.e alpha, beta and gamma for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wuv is the convex combination of pearson,jaccard and trust\n",
    "#it is calculated between user u and user v\n",
    "\n",
    "def WUV(alpha,beta,gamma,u,v):\n",
    "    pcc=calculateSimilarity(u,v,test,df_rating)\n",
    "    trust=trust_in_users[u-1][v-1]\n",
    "    jac=jaccard(trust_in_users[u-1],trust_in_users[v-1])\n",
    "    temp_total=alpha*pcc + beta*trust + gamma*jac\n",
    "    total=round(temp_total,2)\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#jaccard is needed to calculate wuv \n",
    "\n",
    "def jaccard(a, b):\n",
    "    intersection=0\n",
    "    union=0\n",
    "    for i in range(0,total_users):\n",
    "        if(a[i]!=0 and b[i]!=0):\n",
    "            intersection +=1\n",
    "            union +=1\n",
    "        elif(a[i]!=0):\n",
    "            union +=1\n",
    "        elif(b[i]!=0):\n",
    "            union +=1\n",
    "    return float(intersection/union)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code predicts the rating for a given user and movie by taking the trust and similarity into consideration\n",
    "\n",
    "def predict_rating(final_clusters,userFromTest,userBelongsToCluster,itemid,alpha,beta,gamma):\n",
    "#     userBelongsToCluster=targetClusterTestUserDict[userFromTest]\n",
    "    sum1=0\n",
    "    sum2=0\n",
    "    for i in range(0,len(final_clusters[userBelongsToCluster])):\n",
    "        clusterUser=final_clusters[userBelongsToCluster][i]\n",
    "        rowNum=df_rating[(df_rating.userId==clusterUser)&(df_rating.movieId==itemid)].empty\n",
    "        if(not rowNum):\n",
    "            clusterUserRating=df_rating[(df_rating.userId==clusterUser)&(df_rating.movieId==itemid)]['rating'].tolist()[0]\n",
    "#             print(\"rating=\",clusterUserRating,\"end\")\n",
    "#             print(clusterUserRating.shape)\n",
    "            temp_wuv=WUV(alpha,beta,gamma,userFromTest,clusterUser)\n",
    "            sum1+=temp_wuv*clusterUserRating\n",
    "            sum2+=abs(temp_wuv)\n",
    "    if(sum2==0):\n",
    "        sum2=1\n",
    "       \n",
    "    prediction=sum1/sum2\n",
    "    return round(prediction,2)\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code calculates the mean absoluter error of the system\n",
    "\n",
    "def calc_MAE(a,b,c,cluster,targetClusterTestUserDict,final_clusters):\n",
    "    real_rating=[]\n",
    "    predicted_rating=[]\n",
    "    length=test.shape[0]\n",
    "    \n",
    "    for i in range(0,length):\n",
    "        \n",
    "        userBelongsToCluster=targetClusterTestUserDict[test.iloc[i]['userId']]\n",
    "        \n",
    "        if(userBelongsToCluster==cluster):\n",
    "            real_rating.append(test.iloc[i]['rating'])\n",
    "            temp_rating=predict_rating(final_clusters,test.iloc[i]['userId'],cluster,test.iloc[i]['movieId'],a,b,c)\n",
    "            predicted_rating.append(temp_rating)\n",
    "    \n",
    "    diff = [abs(x - y) for x, y in zip(real_rating, predicted_rating)]\n",
    "    diff_sum=sum(diff)\n",
    "    length=len(diff)\n",
    "#     print(real_rating)\n",
    "#     print(predicted_rating)\n",
    "    if(length != 0):\n",
    "        mae=diff_sum/length\n",
    "    else:\n",
    "        mae=0\n",
    "    return mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#this code checks which value of alpha,beta and gamma gives the minimum mean absolute error for a given cluster\n",
    "\n",
    "def optimal_parameter(cluster,targetClusterTestUserDict,final_clusters):\n",
    "    min=999\n",
    "    temp_alpha=0\n",
    "    temp_beta=0\n",
    "    temp_gamma=1\n",
    "    for i in range(0,11,1):\n",
    "        for j in range(0,11,1):\n",
    "            a=0.1*i\n",
    "            b=0.1*j\n",
    "            c=1-a-b\n",
    "            mae = calc_MAE(a,b,c,cluster,targetClusterTestUserDict,final_clusters)\n",
    "            if(mae < min):\n",
    "                min = mae\n",
    "                temp_alpha = a\n",
    "                temp_beta = b\n",
    "                temp_gamma = c\n",
    "    alpha=round(temp_alpha,2)\n",
    "    beta=round(temp_beta,2)\n",
    "    gamma=round(temp_gamma,2)\n",
    "    return alpha,beta,gamma\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code assigns optimal values of alpha,beta and gamma for each cluster\n",
    "\n",
    "def ABGof_cluster():\n",
    "    file.write(\"------------------------Started Generating Feasible Partitioning--------------------------------------------\\n\")\n",
    "    final_clusters=feasible_partitioning(70)\n",
    "#     print(final_clusters)\n",
    "    file.write(\"Completed Feasible Partitioning!!!\\n\")\n",
    "\n",
    "    file.write(\"------------------------Printing the output of feasible partitioning at MARC=70--------------------------\\n\")\n",
    "    file.write(\"------------------------Printing final_clusters variable values for each cluster------------------------\\n\")\n",
    "    \n",
    "    for item in final_clusters:\n",
    "        file.write(\"[\")\n",
    "        for sub_item in item:\n",
    "            file.write(\"%s,\" % sub_item)\n",
    "        file.write(\"]\\n\")\n",
    "    \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    targetClusterTestUserDict=testUserDict(final_clusters)\n",
    "    length=len(final_clusters)\n",
    "    final_alpha=[]\n",
    "    final_beta=[]\n",
    "    final_gamma=[]\n",
    "    for i in range(0,length):\n",
    "        tempa,tempb,tempc=optimal_parameter(i,targetClusterTestUserDict,final_clusters)\n",
    "        final_alpha.append(tempa)\n",
    "        final_beta.append(tempb)\n",
    "        final_gamma.append(tempc)\n",
    "    \n",
    "    file.write(\"Completed Calculation!!!\\n\")\n",
    "    \n",
    "    file.write(\"------------------------Printing final_alpha variable values for each cluster------------------------\\n\")\n",
    "    \n",
    "    for sub_item in final_alpha:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "        \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    file.write(\"------------------------Printing final_beta variable values for each cluster------------------------\\n\")\n",
    "    \n",
    "    for sub_item in final_beta:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    \n",
    "    file.write(\"------------------------Printing final_gamma variable values for each cluster------------------------\\n\")\n",
    "    \n",
    "    for sub_item in final_gamma:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    file.write(\"----------------------------------End Of Output File------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    \n",
    "#     print(final_alpha)\n",
    "#     print(final_beta)\n",
    "#     print(final_gamma)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"Started Calculating optimal parameters i.e alpha, beta and gamma for each cluster............\\n\")\n",
    "ABGof_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Novel_2D_Graph_Implementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
