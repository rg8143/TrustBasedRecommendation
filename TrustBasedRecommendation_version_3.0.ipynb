{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dzTyNro1RvY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file output.txt for writing outputs..........\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating file for taking outputs \n",
    "print(\"Opening file output.txt for writing outputs..........\")\n",
    "file = open(\"output.txt\",'w')\n",
    "file.write(\"Dataset Used is custom_trust and custom_rating\\n\")\n",
    "file.write(\"Loading the rating and trust dataset.....\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading The Rating and Trust Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "YE96i5bu1Rve",
    "outputId": "bf73c9de-79df-493b-bf0a-a68d7fc15edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset.........\n",
      "dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "print(\"Loading the dataset.........\")\n",
    "df_trust=pd.read_csv(\"trust_data.txt\",delim_whitespace=True,encoding=\"utf-8\", skipinitialspace=True)\n",
    "\n",
    "df_rating = pd.read_csv(\"ratings_data.txt\")\n",
    "df_rating = df_rating[(df_rating.userId<=100)&(df_rating.movieId<=4200)]\n",
    "df_rating = df_rating.reset_index(drop=True)\n",
    "file.write(\"Dataset Loaded Successfully!!!\\n\")\n",
    "df_trust = df_trust[(df_trust.user1<=100)&(df_trust.user2<=100)]\n",
    "df_trust = df_trust.reset_index(drop=True)\n",
    "print(\"dataset loaded successfully!\")\n",
    "# test=df_rating[7903:]\n",
    "# test\n",
    "# df_trust\n",
    "\n",
    "# temp=df_rating.sample(10).reset_index(drop=True)\n",
    "# temp\n",
    "# total_rows = df_rating.shape[0]\n",
    "# total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mov =df_rating.movieId.unique()\n",
    "# # mov\n",
    "# mov2=df_rating.sort_values(['movieId'], ascending=[True])\n",
    "# mov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as the partitioning of dataset is only done for rating not for trust so below line finds the overall users in the system\n",
    "temp1 =df_rating.userId.unique()\n",
    "temp2 = df_rating.userId.unique().shape[0]\n",
    "total_users_for_trust=temp1[temp2-1]\n",
    "file.write(\"Dividing The Rating Dataset into training and test.....\\n\")\n",
    "# total_users_for_trust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing The Rating Dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "colab_type": "code",
    "id": "BawsKQRb1Rvn",
    "outputId": "92cbabb6-3de4-48fa-ecbb-f6585850ed05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividing the dataset into training and test(80:20)\n",
    "\n",
    "train=df_rating[0:3828]\n",
    "test=df_rating[3828:]\n",
    "test = test.reset_index(drop=True)\n",
    "#df_rating is the training part of rating dataset and test is the testing part of the dataset\n",
    "df_rating=train\n",
    "# print(\"dataset divided successfully!!!\")\n",
    "file.write(\"completed!!!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing the matrices for trust propagation,similarity and user pair distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0pb6hda1Rvt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_users calculates the total users in the training dataset \n",
    "#unique_user_list finds the unique users from the training dataset as there are redundant rows of the same user in the rating dataset\n",
    "\n",
    "file.write(\"Intializing the matrices for trust propagation,similarity and user pair distances.................\\n\")\n",
    "print(\"Intializing the matrices for trust propagation,similarity and user pair distances.................\")\n",
    "total_users = df_rating.userId.unique().shape[0]\n",
    "unique_user_list = df_rating.userId.unique().tolist()\n",
    "\n",
    "# following matrix i.e similarity is used for holding the pcc between a pair of users\n",
    "# similarity = [[0 for x in range(total_users)] for y in range(total_users)]\n",
    "similarity = np.zeros((total_users,total_users))\n",
    "\n",
    "# following matrix i.e trust_in_users is used for holding the chain of trust between a pair of users\n",
    "# trust_in_users = [[0 for x in range(total_users_for_trust)] for y in range(total_users_for_trust)]\n",
    "trust_in_users = np.zeros((total_users_for_trust,total_users_for_trust))\n",
    "\n",
    "# following matrix i.e user_pair_distance is used for holding the distance between a pair of users\n",
    "#the formula used for calculating the distances between users is taken from novel 2d graph research paper\n",
    "#distance of 9 tells that there is no way between pair of users to calculate distance so 9 denotes the infinity\n",
    "# user_pair_distance = [[0 for x in range(total_users)] for y in range(total_users)]\n",
    "user_pair_distance = np.zeros((total_users,total_users))\n",
    "\n",
    "print(\"matrix intialization completed!!!\")\n",
    "file.write(\"completed!!!\\n\")\n",
    "\n",
    "file.write(\"Construction of Novel 2D Graph started........\\n\")\n",
    "print(\"-----------Construction of Novel 2D Graph started-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rating = pd.read_csv(\"custom_rating.csv\")\n",
    "\n",
    "\n",
    "#this function calculates similarity between the pair of user as needed using the pearson similarity coefficient\n",
    "def calculateSimilarity(i,j,dataset1,dataset2):\n",
    "    firstUser = dataset1[dataset1.userId==i]\n",
    "    firstUser.columns = ['userId1','movieId','rating1']\n",
    "    \n",
    "    secondUser = dataset2[dataset2.userId==j]\n",
    "    secondUser.columns = ['userId2','movieId','rating2']\n",
    "    userRatings = pd.merge(firstUser,secondUser,on ='movieId')\n",
    "    \n",
    "\n",
    "    if(userRatings.shape[0]>1):\n",
    "        \n",
    "        \n",
    "        firstUserRatingMean= firstUser[\"rating1\"].mean()\n",
    "        secondUserRatingMean= secondUser[\"rating2\"].mean()\n",
    "\n",
    "\n",
    "        firstUsertemp1=userRatings[\"rating1\"]-firstUserRatingMean\n",
    "        firstUsertemp1 =firstUsertemp1.fillna(0)\n",
    "        firstUsertemp1sq=firstUsertemp1*firstUsertemp1\n",
    "        firstUsertemp1sqsum=sum(firstUsertemp1sq)\n",
    "        firstUsertemp1sqrt =math.sqrt(firstUsertemp1sqsum)\n",
    "\n",
    "\n",
    "        secondUsertemp1=userRatings[\"rating2\"]-secondUserRatingMean\n",
    "        secondUsertemp1=secondUsertemp1.fillna(0)\n",
    "        secondUsertemp1sq=secondUsertemp1*secondUsertemp1\n",
    "        secondUsertemp1sqsum=sum(secondUsertemp1sq)\n",
    "        secondUsertemp1sqrt =math.sqrt(secondUsertemp1sqsum)\n",
    "\n",
    "        firstSecondtemp1=firstUsertemp1*secondUsertemp1\n",
    "        firstSecondtemp1=firstSecondtemp1.fillna(0)\n",
    "        firstSecondtemp1sum=sum(firstSecondtemp1)\n",
    "\n",
    "        firstSecondtemp1sqrtMulti=firstUsertemp1sqrt*secondUsertemp1sqrt\n",
    "        if(firstSecondtemp1sqrtMulti!=0):\n",
    "            temp_pcc=firstSecondtemp1sum/firstSecondtemp1sqrtMulti\n",
    "        else:\n",
    "            temp_pcc=0.00\n",
    "    \n",
    "        \n",
    "        pcc=round(temp_pcc,2)\n",
    "        \n",
    "        \n",
    "#         temp_pcc = np.corrcoef(userRatings['rating1'].tolist(),userRatings['rating2'].tolist())[0, 1]\n",
    "    \n",
    "    else:\n",
    "        pcc = 0\n",
    "    return pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simi=calculateSimilarity(1,5,df_rating,df_rating)\n",
    "# simi\n",
    "# # temp = df_rating['rating']-1\n",
    "# # temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.0\n",
       "1     2.0\n",
       "2     2.0\n",
       "3     2.0\n",
       "4     2.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp1 = df_rating['rating'].head()-1\n",
    "# # temp1\n",
    "# temp2 = df_rating['rating']-2\n",
    "# # temp2\n",
    "# temp3 = df_rating['rating'].head()-temp2\n",
    "# temp3=temp3.fillna(0)\n",
    "# temp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of Novel 2D Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "nl1nb-A11Rvv",
    "outputId": "103c525a-c059-4c7c-e738-47f39dd1a232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   1.   1.   1.   0.5  0.   0.33 1.   0.5  0.5 ]\n",
      " [1.   1.   0.5  1.   1.   0.   0.5  0.5  1.   0.33]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.33 0.   0.5  0.   1.   0.   1.   1.   0.5  0.5 ]\n",
      " [0.   0.   0.   1.   0.   1.   0.   0.   0.   0.  ]\n",
      " [0.5  0.33 1.   0.33 0.   0.   1.   1.   1.   0.5 ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.   0.   1.  ]\n",
      " [1.   0.5  0.5  0.5  0.33 0.   0.   0.5  1.   0.33]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#module for calculating similarity currently pearson similarity is used\n",
    "\n",
    "# # g is a graph that is used to show pcc similarity between users\n",
    "# g = nx.DiGraph()\n",
    "# g.add_nodes_from(unique_user_list)\n",
    "\n",
    "\n",
    "# #this function calculates similarity between the pair of user as needed using the pearson similarity coefficient\n",
    "# def calculateSimilarity(i,j,dataset1,dataset2):\n",
    "#     firstUser = dataset1[dataset1.userId==i]\n",
    "#     firstUser.columns = ['userId1','movieId','rating1']\n",
    "#     secondUser = dataset2[dataset2.userId==j]\n",
    "#     secondUser.columns = ['userId2','movieId','rating2']\n",
    "#     userRatings = pd.merge(firstUser,secondUser,on ='movieId')\n",
    "#     if(userRatings.shape[0]>1):\n",
    "#         temp_pcc = np.corrcoef(userRatings['rating1'].tolist(),userRatings['rating2'].tolist())[0, 1]\n",
    "#         pcc=round(temp_pcc,2)\n",
    "#     else:\n",
    "#         pcc = 0\n",
    "#     return pcc\n",
    "\n",
    "print(\"pcc similarity calculation started.........\")\n",
    "# this is used to calculate similarity between every pair of users\n",
    "for i in range(0,total_users):\n",
    "    print(\"pcc similarity calculation started for user id.........\",i+1)\n",
    "    for j in range(0,total_users):\n",
    "        if(i==j):\n",
    "            similarity[i][j]=round(1.000, 2)\n",
    "        else:\n",
    "            y= round(calculateSimilarity(i+1,j+1,df_rating,df_rating), 2)\n",
    "            if(not np.isnan(y)):\n",
    "                similarity[i][j]= y\n",
    "print(\"pcc similarity completed!!!\")\n",
    "#      \n",
    "# #for adding edges and weights to the graph g\n",
    "# for i in range(0,total_users):\n",
    "#     for j in range(i+1,total_users):\n",
    "#         if(similarity[i][j]>0):\n",
    "#             g.add_edge(i+1,j+1, weight=similarity[i][j])\n",
    "\n",
    "            \n",
    "# #this code shows the edge labels and final visualization of the graph \n",
    "# #here edge weights are pearson coorelation coefficient\n",
    "# pos = nx.circular_layout(g)\n",
    "# nx.draw(g,pos,with_labels=True)\n",
    "# nx.draw_networkx_edge_labels(g,pos)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"pcc_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()  \n",
    "\n",
    "# print(similarity)\n",
    "print(\"printing similarity matrix................\")\n",
    "file.write(\"-----------------Printing the similarity matrix------------------------------\\n\")\n",
    "\n",
    "for item in similarity:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"printing of similarity matrix completed!!!\")\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#module for calculating chain of trust between users\n",
    "\n",
    "# # t is a graph that is used to show trust between users\n",
    "print(\"started making graph for trust propagation.....\")\n",
    "t = nx.DiGraph()\n",
    "t.add_nodes_from(unique_user_list)\n",
    "\n",
    "rows_in_trust = df_trust.shape[0]\n",
    "\n",
    "for i in range(0,rows_in_trust):\n",
    "    t.add_edge(df_trust.loc[i, 'user1'],df_trust.loc[i, 'user2'])\n",
    "print(\"completed making graph for trust propagation!!!\")\n",
    "\n",
    "# pos = nx.circular_layout(t)\n",
    "# nx.draw(t,pos,with_labels=True)\n",
    "# # nx.draw_networkx_edge_labels(t,pos)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"trust_chain_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()\n",
    "\n",
    "# here input x is based on the six degree theory\n",
    "# if x is 2 then it means while calculating trust between two user\n",
    "# a and b there can be atmost 2 node present between them\n",
    "def calculateTrustChain(x):\n",
    "    for i in range(1,total_users_for_trust+1):\n",
    "        for j in range(1,total_users_for_trust+1):\n",
    "            if(i!=j):\n",
    "                print(\"calculating chain of trust between user id...\",i,\"...and user id...\",j)\n",
    "                try:\n",
    "                    path_length = nx.shortest_path_length(t,source=i,target=j)\n",
    "                    if(path_length <= x+1):\n",
    "                        trust_in_users[i-1][j-1] = round(pow(path_length,-1),2)\n",
    "                    else:\n",
    "                        trust_in_users[i-1][j-1] = 0\n",
    "                except nx.NetworkXNoPath:\n",
    "                    trust_in_users[i-1][j-1] = 0\n",
    "            else:\n",
    "                trust_in_users[i-1][j-1] = 1\n",
    "                \n",
    "                    \n",
    "\n",
    "print(\"calculating chain of trust with at max 2 hops.....\")                    \n",
    "file.write(\"\\n---------calculating chain of trust using at max 2 hops between two users----------\\n\")      \n",
    "calculateTrustChain(2)\n",
    "print(\"chain of trust completed successfully!!!\")\n",
    "print(\"printing trust_in_users matrix to file.........\")\n",
    "# print(trust_in_users)\n",
    "\n",
    "file.write(\"-----------------Printing the trust_in_users matrix------------------------------\\n\")\n",
    "\n",
    "for item in trust_in_users:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"trust_in_users matrix printed successfully!!!\")\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "# #every edge of combined_graph is double weighted i.e having similarity and trust as its weights\n",
    "# #and the users as its nodes\n",
    "# combined_graph = nx.DiGraph()\n",
    "# combined_graph.add_nodes_from(unique_user_list)\n",
    "\n",
    "# #this loop adds edges between two nodes if there exist any edge\n",
    "# for i in range(0,total_users):\n",
    "#     for j in range(0,total_users):\n",
    "#         if(i!=j):\n",
    "#             if((trust_in_users[i][j]!=0) or (similarity[i][j]!=0)):\n",
    "#                 combined_graph.add_edge(i+1,j+1, label='('+str(similarity[i][j])+','+str(trust_in_users[i][j])+')')\n",
    "                \n",
    "# #this code shows the combined graph in circular fashion\n",
    "# pos = nx.circular_layout(combined_graph)\n",
    "# nx.draw(combined_graph,pos,with_labels=True,node_size=100,font_size=10)\n",
    "# nx.draw_networkx_edge_labels(combined_graph,pos,font_size=8)\n",
    "# plt.draw()\n",
    "# plt.savefig(\"pcc_and_trust_combined_graph.png\")\n",
    "# plt.gcf().clear()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "# This module is to make clusters out of given novel 2d graph\n",
    "\n",
    "#these loops are calculating the distances between a pair of users\n",
    "#the formula used for calculating distance is taken from novel 2d graph algorithm\n",
    "#distance of 9 tells that there is no way between pair of users to calculate distance so it denotes infinity\n",
    "\n",
    "print(\"started calculating user_pair_distance...........\")\n",
    "for i in range(0,total_users):\n",
    "    for j in range(0,total_users):\n",
    "        if(similarity[i][j]!=0 or trust_in_users[i][j]!=0):\n",
    "            print(\"calculating user_pair_distance between user id...\",i+1,\"...and user id...\",j+1)\n",
    "            d_s = 1-similarity[i][j]\n",
    "            d_t = 1-trust_in_users[i][j]\n",
    "            d_s_2 = d_s**2\n",
    "            d_t_2 = d_t**2\n",
    "            temp = d_s_2+d_t_2\n",
    "            distance = round(temp**0.5,2)\n",
    "            user_pair_distance[i][j]=distance\n",
    "        else:\n",
    "            #here distance of 9 tells that there is no way between this pair of users so infinite distance\n",
    "            user_pair_distance[i][j]=9\n",
    "            \n",
    "print(\"user_pair_distance calculated successfully!!!\")\n",
    "\n",
    "# print(user_pair_distance)\n",
    "print(\"-----------Construction of Novel 2D Graph completed successfully!!!-----------------\")\n",
    "file.write(\"Construction of Novel 2D Graph Completed!!!!\\n\")\n",
    "print(\"printing user_pair_distance to file....\")\n",
    "file.write(\"-----------------Printing the user_pair_distance matrix------------------------------\\n\")\n",
    "\n",
    "for item in user_pair_distance:\n",
    "    for sub_item in item:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "file.write(\"\\n\\n\\n\")\n",
    "print(\"user_pair_distance writing successfull!!!\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "file.write(\"----------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Feasible Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.write(\"Started Generating Feasible Partitioning............\\n\")\n",
    "\n",
    "def kmedoids(number_of_clusters):\n",
    "    chosen_clusters=[]\n",
    "    final_clusters=[]\n",
    "    print(\"-----inside kemdoids chosing...\",number_of_clusters,\"......random cluster centers----\")\n",
    "    for i in range(0,number_of_clusters):\n",
    "        x=random.randint(1,total_users)\n",
    "        while(x in chosen_clusters):\n",
    "            x=random.randint(1,total_users)\n",
    "        chosen_clusters.append(x)\n",
    "    for j in chosen_clusters:\n",
    "        final_clusters.append([j])\n",
    "    cont=True\n",
    "    print(\"checking for corresponding cluster for each users(inside kmedoids).....!!! --Total_clustesr=\",number_of_clusters)\n",
    "    while(cont):\n",
    "        for i in range(0,total_users):\n",
    "            print(\"checking corresponding cluster for user id (inside kmedoids)....\",i+1,\"--Total_clusters=\",number_of_clusters)\n",
    "            if(not any(i+1 in sublist for sublist in final_clusters)):\n",
    "                min_distance=10\n",
    "                allocate_cluster=0\n",
    "                for j in range(0,number_of_clusters):\n",
    "                    temp_cluster=final_clusters[j][0]\n",
    "                    if(min_distance>=user_pair_distance[i][temp_cluster-1]):\n",
    "                        min_distance=user_pair_distance[i][temp_cluster-1]\n",
    "                        allocate_cluster=j\n",
    "                final_clusters[allocate_cluster].append(i+1)\n",
    "        cont=False\n",
    "        row_num=0\n",
    "        modification_dict={}\n",
    "        \n",
    "        print(\"All users mapped to their corresponding clusters(inside kmedoids)!!!---Total_clusters : \",number_of_clusters)\n",
    "        print(\"Checking each cluster for user which have minimum distance from all users in the same cluster(inside kmedoids).!-- Total_clusters :\",number_of_clusters)\n",
    "        \n",
    "        for i in final_clusters:\n",
    "            min_cluster_distance=99999\n",
    "            for j in range(0,len(i)):\n",
    "                total_sum=0\n",
    "                avg=0\n",
    "                for k in range(0,len(i)):\n",
    "                    if(i[j]!=i[k]):\n",
    "                        total_sum +=user_pair_distance[i[j]-1][i[k]-1]\n",
    "                avg=total_sum/len(i)\n",
    "                if(min_cluster_distance>avg):\n",
    "                    min_cluster_distance=avg\n",
    "                    min_cluster=i[j]\n",
    "            if(min_cluster!=i[0]):\n",
    "                cont=True\n",
    "                modification_dict[row_num]=min_cluster                \n",
    "            row_num+=1            \n",
    "        if(cont):\n",
    "            print(\"one of the cluster center has changed(inside kmedoids).........\")\n",
    "            print(\"Repeating the clustering with latest users as center(inside kmedoids).........\")\n",
    "            final_clusters=[]\n",
    "            for z in chosen_clusters:\n",
    "                    final_clusters.append([z])\n",
    "            for key in modification_dict:\n",
    "                    final_clusters[key][0]=modification_dict[key]\n",
    "#     print(chosen_clusters)\n",
    "#     print(final_clusters)\n",
    "#     for i in range(0,len(final_clusters)):\n",
    "#         cluster_centers.append(final_clusters[i][0])\n",
    "    print(\"clustering into....\",number_of_clusters,\".....clusters completed(inside kmedoids)!!!--Total clusters formed:\",number_of_clusters)\n",
    "    return final_clusters    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this code checks the distance of each user in the test dataset with the \n",
    "#clusters and assigns nearest cluster to the user in the test dataset\n",
    "\n",
    "def testUserDict(cluster_centers):\n",
    "    print(\"checking test dataset user for their corresponding clusters...\")\n",
    "    testSetUser=test.userId.unique().tolist()\n",
    "    targetClusterTestUserDict={}\n",
    "    \n",
    "#     print(cluster_centers)\n",
    "\n",
    "\n",
    "    for i in range(0,len(testSetUser)):\n",
    "        nearestClusterIndex=0\n",
    "        minDistance=10\n",
    "        print(\"checking test dataset user for their corresponding clusters...test Dataset row--\",i+1)\n",
    "        for j in range(0,len(cluster_centers)):\n",
    "\n",
    "            pcc_simi=calculateSimilarity(testSetUser[i],cluster_centers[j][0],test,df_rating)\n",
    "            temp1=testSetUser[i]-1\n",
    "            temp2=cluster_centers[j][0]-1\n",
    "            trust_simi=trust_in_users[temp1][temp2]\n",
    "            if(pcc_simi!=0 or trust_simi!=0):\n",
    "                d_s = 1-pcc_simi\n",
    "                d_t = 1-trust_simi\n",
    "                d_s_2 = d_s**2\n",
    "                d_t_2 = d_t**2\n",
    "                temp = d_s_2+d_t_2\n",
    "                distance = round(temp**0.5,2)\n",
    "            else:\n",
    "                #here distance of 9 tells that there is no way between this pair of users so infinite distance\n",
    "                distance=9\n",
    "            if(minDistance>distance):\n",
    "                minDistance=distance\n",
    "                nearestClusterIndex=j\n",
    "        targetClusterTestUserDict[testSetUser[i]]=nearestClusterIndex\n",
    "    print(\"completed mapping of test dataset users into corresponding clusters successfully(inside testuserdict)!!!\")\n",
    "    return targetClusterTestUserDict\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#it calculates rating coverage for the system using the test dataset\n",
    "def rating_coverage(clusters,targetClusterTestUserDict):\n",
    "    count=0\n",
    "    length=test.shape[0]\n",
    "    for i in range(0,length):\n",
    "        print(\"calculating rating coverage....for test Dataset row.....\",i+1,\"--for number of clusters:\",len(clusters))\n",
    "        userBelongsToCluster=targetClusterTestUserDict[test.iloc[i]['userId']]\n",
    "        itemid=test.iloc[i]['movieId']\n",
    "        for j in clusters[userBelongsToCluster]:\n",
    "            rowNum=df_rating[(df_rating.userId==j)&(df_rating.movieId==itemid)].empty\n",
    "            if(not rowNum):\n",
    "                count+=1\n",
    "                break;       \n",
    "    rc=count/length\n",
    "    rc=round(rc,2)\n",
    "    print(\"rating coverage completed!!!--for number of clusters:\",len(clusters))\n",
    "    return rc*100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#it checks and decides optimal number of clusters according to given rate of coverage\n",
    "def feasible_partitioning(MARC):\n",
    "    rc=100\n",
    "    final_rc=0\n",
    "    i=1\n",
    "    partition1=[]\n",
    "    partition2=[]\n",
    "    while(rc>=MARC):\n",
    "        i=i+1\n",
    "        print(\"------------partioning the system into....\",i,\"........clusters------------------\")\n",
    "        partition2=kmedoids(i)\n",
    "        targetClusterTestUserDict=testUserDict(partition2)\n",
    "        final_rc=rc\n",
    "        rc = rating_coverage(partition2,targetClusterTestUserDict)\n",
    "        partition1=partition2\n",
    "#     final_cluster=partition1\n",
    "    \n",
    "    print(\"\\n\\n\\n######################################################################\\n\\n\\n\")\n",
    "    print(\"Total Partitions/clusters formed after feasible partitioning is : \",len(partition1))\n",
    "    print(\"\\n\\n\\n######################################################################\")\n",
    "    \n",
    "    return partition1,final_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file.write(\"------------------------Started Generating Feasible Partitioning--------------------------------------------\\n\")\n",
    "\n",
    "# abc=feasible_partitioning(70)\n",
    "# file.write(\"Completed Feasible Partitioning!!!\\n\")\n",
    "\n",
    "# file.write(\"-----------------------Printing the output of feasible partitioning at MARC=70--------------------\\n\")\n",
    "# # abc\n",
    "\n",
    "# for item in abc:\n",
    "#     for sub_item in item:\n",
    "#         file.write(\"%s\\t\" % sub_item)\n",
    "#     file.write(\"\\n\")\n",
    "\n",
    "# file.write(\"\\n\\n\\n\")\n",
    "\n",
    "# file.write(\"---------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cluster_performance_mae(a,b,c,cluster,final_clusters,jaccard_similarity_dict,rows_to_predict):\n",
    "    \n",
    "    real_rating=[]\n",
    "    predicted_rating=[]\n",
    "    length=rows_to_predict.shape[0]\n",
    "    \n",
    "    for i in range(0,length):\n",
    "        \n",
    "        print(\"calculating mae for cluster no.--\",cluster+1,\"---Total_cluster = \",len(final_clusters),\"--checking rows_to_predict dataset row--\",i+1)    \n",
    "        \n",
    "        real_rating.append(rows_to_predict.iloc[i]['rating'])\n",
    "        temp_rating=predict_rating(final_clusters,rows_to_predict.iloc[i]['userId'],cluster,rows_to_predict.iloc[i]['movieId'],a,b,c,jaccard_similarity_dict,similarity)\n",
    "        predicted_rating.append(temp_rating)\n",
    "    \n",
    "    diff = [abs(x - y) for x, y in zip(real_rating, predicted_rating)]\n",
    "    diff_sum=sum(diff)\n",
    "    length=len(diff)\n",
    "    \n",
    "    if(length != 0):\n",
    "        mae=diff_sum/length\n",
    "    else:\n",
    "        mae=99\n",
    "    return mae\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {2: 5}, 2: {1: 6}, 3: {}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = [[1,2,3],[4,5]]\n",
    "# temp2=temp[1]\n",
    "# temp3=df_rating[df_rating['userId'].isin(temp2)].reset_index(drop=True)\n",
    "# temp3=temp3.sample(5)\n",
    "# temp3\n",
    "\n",
    "# temp = {2:{1:5,6:7}}\n",
    "# # temp[2][7]\n",
    "# temp={9:{}}\n",
    "# temp2={}\n",
    "# temp2[1]=5\n",
    "# temp2[3]=6\n",
    "# temp[9][2]=0\n",
    "# temp[8]=temp2\n",
    "# temp[8][1]\n",
    "# temp[9][2]\n",
    "\n",
    "# temp[5]=10\n",
    "# temp[6]={}\n",
    "# temp[6][1]=99\n",
    "# temp\n",
    "# jaccard_similarity_dict={}\n",
    "# for i in temp[0]:\n",
    "#         temp1={}\n",
    "#         jaccard_similarity_dict[i]=temp1\n",
    "# jaccard_similarity_dict[1][2]=5\n",
    "# jaccard_similarity_dict[2][1]=6\n",
    "# jaccard_similarity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating optimal parameters i.e alpha, beta and gamma for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wuv is the convex combination of pearson,jaccard and trust\n",
    "#it is calculated between user u and user v\n",
    "\n",
    "def WUV(alpha,beta,gamma,u,v,jaccard_similarity_dict,testuser_pcc_similarity_dict):\n",
    "    print(\"calculating wuv for (alpha,beta,gamma,u,v) :\",alpha,beta,gamma,u,v)\n",
    "#     pcc=calculateSimilarity(u,v,test,df_rating)\n",
    "    pcc=testuser_pcc_similarity_dict[u-1][v-1]\n",
    "    trust=trust_in_users[u-1][v-1]\n",
    "#     jac=jaccard(trust_in_users[u-1],trust_in_users[v-1])\n",
    "    jac=jaccard_similarity_dict[u][v]\n",
    "    temp_total=alpha*pcc + beta*trust + gamma*jac\n",
    "    total=round(temp_total,2)\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#jaccard is needed to calculate wuv \n",
    "\n",
    "def jaccard(a, b):\n",
    "    print(\"calculating jaccard!!!....\")\n",
    "    intersection=0\n",
    "    union=0\n",
    "    for i in range(0,total_users):\n",
    "        if(a[i]!=0 and b[i]!=0):\n",
    "            intersection +=1\n",
    "            union +=1\n",
    "        elif(a[i]!=0):\n",
    "            union +=1\n",
    "        elif(b[i]!=0):\n",
    "            union +=1\n",
    "    temp_jac = float(intersection/union)\n",
    "    jac=round(temp_jac,2)\n",
    "    return jac\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code predicts the rating for a given user and movie by taking the trust and similarity into consideration\n",
    "\n",
    "def predict_rating(final_clusters,userFromTest,userBelongsToCluster,itemid,alpha,beta,gamma,jaccard_similarity_dict,testuser_pcc_similarity_dict):\n",
    "#     userBelongsToCluster=targetClusterTestUserDict[userFromTest]\n",
    "    sum1=0\n",
    "    sum2=0\n",
    "    print(\"predicting rating for user id(test)\",userFromTest,\"movie id:\",itemid,\"--with (alpha,beta,gamma) as \",alpha,beta,gamma)\n",
    "    for i in range(0,len(final_clusters[userBelongsToCluster])):\n",
    "        clusterUser=final_clusters[userBelongsToCluster][i]\n",
    "        if(clusterUser!=userFromTest):\n",
    "            rowNum=df_rating[(df_rating.userId==clusterUser)&(df_rating.movieId==itemid)].empty\n",
    "            if(not rowNum):\n",
    "                clusterUserRating=df_rating[(df_rating.userId==clusterUser)&(df_rating.movieId==itemid)]['rating'].tolist()[0]\n",
    "                temp_wuv=WUV(alpha,beta,gamma,userFromTest,clusterUser,jaccard_similarity_dict,testuser_pcc_similarity_dict)\n",
    "                sum1+=temp_wuv*clusterUserRating\n",
    "                sum2+=abs(temp_wuv)\n",
    "    if(sum2==0):\n",
    "        sum2=1\n",
    "       \n",
    "    prediction=sum1/sum2\n",
    "    return round(prediction,2)\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code calculates the mean absoluter error of the system\n",
    "\n",
    "def calc_MAE_system(alpha_beta_gamma_dict,targetClusterTestUserDict,final_clusters):\n",
    "    real_rating=[]\n",
    "    predicted_rating=[]\n",
    "    length=test.shape[0]\n",
    "    \n",
    "    test_unique_user =test.userId.unique().tolist()\n",
    "    \n",
    "    jaccard_similarity_dict={}\n",
    "    testuser_pcc_similarity_dict={}\n",
    "    \n",
    "    for i in test_unique_user:\n",
    "        temp={}\n",
    "        jaccard_similarity_dict[i]=temp\n",
    "        testuser_pcc_similarity_dict[i-1]=temp\n",
    "        for j in final_clusters[targetClusterTestUserDict[i]]:\n",
    "            jac = jaccard(trust_in_users[i-1],trust_in_users[j-1])\n",
    "            pcc=calculateSimilarity(i,j,test,df_rating)\n",
    "            jaccard_similarity_dict[i][j]=jac \n",
    "            testuser_pcc_similarity_dict[i-1][j-1]=pcc\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,length):\n",
    "        print(\"calculating mae for system---Total_cluster = \",len(final_clusters),\"--checking test dataset row--\",i+1)\n",
    "        userBelongsToCluster=targetClusterTestUserDict[test.iloc[i]['userId']]\n",
    "        real_rating.append(test.iloc[i]['rating'])\n",
    "        temp_rating=predict_rating(final_clusters,test.iloc[i]['userId'],userBelongsToCluster,test.iloc[i]['movieId'],alpha_beta_gamma_dict[userBelongsToCluster]['alpha'],alpha_beta_gamma_dict[userBelongsToCluster]['beta'],alpha_beta_gamma_dict[userBelongsToCluster]['gamma'],jaccard_similarity_dict,testuser_pcc_similarity_dict)\n",
    "        predicted_rating.append(temp_rating)\n",
    "    \n",
    "    diff = [abs(x - y) for x, y in zip(real_rating, predicted_rating)]\n",
    "    diff_sum=sum(diff)\n",
    "    length=len(diff)\n",
    "    \n",
    "    if(length != 0):\n",
    "        mae=diff_sum/length\n",
    "    else:\n",
    "        mae=0\n",
    "    return mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#this code checks which value of alpha,beta and gamma gives the minimum mean absolute error for a given cluster\n",
    "\n",
    "def optimal_parameter(cluster,targetClusterTestUserDict,final_clusters):\n",
    "    min=999\n",
    "    temp_alpha=0\n",
    "    temp_beta=0\n",
    "    temp_gamma=1\n",
    "    length=len(final_clusters[cluster])\n",
    "    \n",
    "    cluster_under_check = final_clusters[cluster]\n",
    "    cluster_under_check_length=len(cluster_under_check)\n",
    "    cluster_under_check_dataset = df_rating[df_rating['userId'].isin(cluster_under_check)].reset_index(drop=True)\n",
    "    cluster_under_check_dataset_length=cluster_under_check_dataset.shape[0]\n",
    "    average_row=cluster_under_check_dataset_length//cluster_under_check_length\n",
    "    \n",
    "    if(average_row>0):\n",
    "        rows_to_predict=cluster_under_check_dataset.sample(average_row)\n",
    "    else:\n",
    "        rows_to_predict=cluster_under_check_dataset\n",
    "    \n",
    "    \n",
    "    jaccard_similarity_dict={}\n",
    "    \n",
    "    for i in final_clusters[cluster]:\n",
    "        temp={}\n",
    "        jaccard_similarity_dict[i]=temp  \n",
    "        \n",
    "    for i in range(0,length):\n",
    "        user1=final_clusters[cluster][i]\n",
    "        for j in range(i+1,length):\n",
    "            user2=final_clusters[cluster][j]\n",
    "            jac= jaccard(trust_in_users[user1-1],trust_in_users[user2-1])\n",
    "            jaccard_similarity_dict[user1][user2]=jac\n",
    "            jaccard_similarity_dict[user2][user1]=jac\n",
    "            \n",
    "    \n",
    "    for i in range(0,11,1):\n",
    "        for j in range(0,11-i,1):\n",
    "            print(\"-----calculating optimal parameter for cluster no....\",cluster+1,\"--with alpha =\",temp_alpha,\"--with beta=\",temp_beta,\"--\")\n",
    "            a=0.1*i\n",
    "            a=round(a,2)\n",
    "            b=0.1*j\n",
    "            b=round(b,2)\n",
    "            c=1-a-b\n",
    "            c=round(c,2)\n",
    "            print(\"calculating mae for cluster--\",cluster+1)\n",
    "#             mae = calc_MAE(a,b,c,cluster,targetClusterTestUserDict,final_clusters)\n",
    "\n",
    "            mae = check_cluster_performance_mae(a,b,c,cluster,final_clusters,jaccard_similarity_dict,rows_to_predict)\n",
    "            print(\"mae calculated for cluster-----\",cluster+1,\"---!!!\")\n",
    "            if(mae < min):\n",
    "                min = mae\n",
    "                temp_alpha = a\n",
    "                temp_beta = b\n",
    "                temp_gamma = c\n",
    "    alpha=round(temp_alpha,2)\n",
    "    beta=round(temp_beta,2)\n",
    "    gamma=round(temp_gamma,2)\n",
    "    print(\"optimal_parameter for cluster no.--\",cluster+1,\"-----------completed!!!\")\n",
    "    print(\"alpha=\",alpha,\"beta=\",beta,\"gamma=\",gamma)\n",
    "    print(\"-------------------------------------------\")\n",
    "    return alpha,beta,gamma\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#this code assigns optimal values of alpha,beta and gamma for each cluster\n",
    "\n",
    "def ABGof_cluster():\n",
    "    \n",
    "    rc=70\n",
    "    \n",
    "    \n",
    "    print(\"------------------------Started Generating Feasible Partitioning--------------------------------------------\")\n",
    "    file.write(\"------------------------Started Generating Feasible Partitioning--------------------------------------------\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_clusters,final_rc=feasible_partitioning(70)\n",
    "    \n",
    "    \n",
    "#     print(final_clusters)\n",
    "    print(\"feasible partitioning successfull!!!\")\n",
    "    file.write(\"Completed Feasible Partitioning!!!\\n\")\n",
    "\n",
    "    file.write(\"------------------------Printing the output of feasible partitioning at MARC=70--------------------------\\n\")\n",
    "    file.write(\"------------------------Printing final_clusters variable values for each cluster------------------------\\n\")\n",
    "    print(\"printing output of feasible into file......\")\n",
    "    for item in final_clusters:\n",
    "        file.write(\"[\")\n",
    "        for sub_item in item:\n",
    "            file.write(\"%s,\" % sub_item)\n",
    "        file.write(\"]\\n\")\n",
    "    \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    print(\"writing completed successfully!!!\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    print(\"calculating testUserDict using final clusters.........\")\n",
    "    targetClusterTestUserDict=testUserDict(final_clusters)\n",
    "    length=len(final_clusters)\n",
    "    final_alpha=[]\n",
    "    final_beta=[]\n",
    "    final_gamma=[]\n",
    "    alpha_beta_gamma_dict={}\n",
    "    for i in range(0,length):\n",
    "        alpha_beta_gamma_dict[i]={}\n",
    "        print(\"-------------------------calculating optimal parameter for cluster no....\",i+1)\n",
    "        tempa,tempb,tempc=optimal_parameter(i,targetClusterTestUserDict,final_clusters)\n",
    "        alpha_beta_gamma_dict[i]['alpha']=tempa\n",
    "        alpha_beta_gamma_dict[i]['beta']=tempb\n",
    "        alpha_beta_gamma_dict[i]['gamma']=tempc\n",
    "        \n",
    "        final_alpha.append(tempa)\n",
    "        final_beta.append(tempb)\n",
    "        final_gamma.append(tempc)\n",
    "    print(\"optimal parameter calculated successfully!!!\")\n",
    "    file.write(\"Completed Calculation!!!\\n\")\n",
    "    \n",
    "    file.write(\"------------------------Printing final_alpha variable values for each cluster------------------------\\n\")\n",
    "    print(\"printing final_alpha to file....\")\n",
    "    for sub_item in final_alpha:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "        \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    print(\"completed!!!\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    file.write(\"------------------------Printing final_beta variable values for each cluster------------------------\\n\")\n",
    "    print(\"printing final_beta to file....\")\n",
    "    for sub_item in final_beta:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    \n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    print(\"completed!!!\")\n",
    "    file.write(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    \n",
    "    file.write(\"------------------------Printing final_gamma variable values for each cluster------------------------\\n\")\n",
    "    print(\"printing final_gamma to file....\")\n",
    "    for sub_item in final_gamma:\n",
    "        file.write(\"%s\\t\" % sub_item)\n",
    "    print(\"completed!!!\")\n",
    "    file.write(\"\\n\\n\\n\")\n",
    "    \n",
    "    print(\"Calculating mean absolute error for the complete system!!!!!!!!!!!!!!!!!!!!\")\n",
    "    \n",
    "    \n",
    "    mae_of_system=calc_MAE_system(alpha_beta_gamma_dict,targetClusterTestUserDict,final_clusters)\n",
    "    print(\"\\n\\n\\n ----------Rating Coverage of system -----------: \",final_rc)\n",
    "    \n",
    "    \n",
    "    file.write(\"\\n\\n\\n ----------Rating Coverage of system -----------: \")\n",
    "    file.write(\"%s\\t\" % final_rc)\n",
    "    \n",
    "    file.write(\"\\n---------------------------------------\\n\\n\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n\\n ----------mae_of_system -----------: \",mae_of_system)\n",
    "    \n",
    "    \n",
    "    file.write(\"\\n\\n\\n ----------mae_of_system -----------: \")\n",
    "    file.write(\"%s\\t\" % mae_of_system)\n",
    "    \n",
    "    file.write(\"\\n---------------------------------------\\n\\n\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    precision=1-(mae_of_system/4)\n",
    "    \n",
    "    print(\"\\n\\n\\n ----------Precision of system -----------: \",precision)\n",
    "    file.write(\"\\n\\n\\n ----------Precision of system  -----------: \")\n",
    "    file.write(\"%s\\t\" % precision)\n",
    "    \n",
    "    file.write(\"\\n---------------------------------------\\n\\n\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    f1_measure=(2*precision*final_rc)/(precision+final_rc)\n",
    "    f1_measure=round(f1_measure,2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n\\n ----------F1 measure of system -----------: \",f1_measure)\n",
    "    file.write(\"\\n\\n\\n ----------F1 measure of system  -----------: \")\n",
    "    file.write(\"%s\\t\" % f1_measure)\n",
    "    \n",
    "    file.write(\"\\n---------------------------------------\\n\\n\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file.write(\"----------------------------------End Of Output File------------------------------------------------------------------------\\n\")\n",
    "    print(\"--------------------------------End---------------------------------------\")\n",
    "    \n",
    "#     print(final_alpha)\n",
    "#     print(final_beta)\n",
    "#     print(final_gamma)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48,\n",
       " 50,\n",
       " 51,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 98,\n",
       " 99,\n",
       " 100]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_unique_user =test.userId.unique().tolist()\n",
    "# test_unique_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"Started Calculating optimal parameters i.e alpha, beta and gamma for each cluster............\\n\")\n",
    "print(\"Started Calculating optimal parameters i.e alpha, beta and gamma for each cluster............\")\n",
    "ABGof_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"closing ouput.txt file............!!!\")\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Novel_2D_Graph_Implementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
